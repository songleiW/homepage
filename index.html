<!DOCTYPE html>
<!-- saved from url=(0040)http://artemsheludko.pw/flexible-jekyll/ -->
<html lang="en">


	
<head>
	
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1833684faf5f254c1bb31386c5780c57";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Songlei Wang's Homepage</title>
        <link rel="shortcut icon" href="img/songlei.jpg"/>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<meta name="keywords" content="Songlei, Harbin Institute of Technology, Shenzhen">
	<meta name="description" content="Songlei Wang's home page">
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<link rel="stylesheet" href="./css/jemdoc.css">
	<title>Songlei Wang, Harbin Institute of Technology, Shenzhen</title>
</head>


	
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Songlei Wang &nbsp 王松磊 </h1><h1>
				</h1></div>

				<h3> PhD student </h3>
				<p>
					<!-- 1037 Luoyu Road,<br> -->
					<!-- National Anti-counterfeit Engineering Research Center,<br> -->
					Harbin Institute of Technology, Shenzhen (HITSZ), <br>
					Shenzhen, Guangdong, China, 518055 <br>
					<br>
					Email: songlei.wang@outlook.com
					       
				</p>
				<p>
					<!-- <a href="paper/CV.pdf"><img src="img/cv_p.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
<!-- 					<a href="https://songleiw.github.io/homepage/"><img src="img/github.jpg" height="40px" style="margin-bottom:-3px"></a> -->
					<!-- <a href="img/weichat.pdf"><img src="img/weichat.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
				</p>
			</td>
			<td>
				<a href="https://songleiw.github.io/homepage/"><img src="img/songlei.jpg" alt="Songlei Wang" border="0" width="350"></a><br>
			</td>
		</tr><tr>
	</tr>
	</tbody>
</table>
	
	



     <h2>Biography</h2>
    <div id="news-content" >
	  <span style="margin: -10px 0px 0px 0px">I am come from Xingtai, Hebei. I am currently an Assistant Professor with the School of Computer Science and Technology, Harbin Institute of Technology,
Shenzhen, China. I received the Ph.D. in the Computer Science Dept. at <a href="https://www.hitsz.edu.cn/index.html">Harbin Institute of Technology (Shenzhen)</a> under the supervision of <a href="http://faculty.hitsz.edu.cn/yeyunming">Prof. Yunming Ye </a>.       
    </div>
	    
    <div id="news-content" >
	  <span style="margin: -10px 0px 0px 0px"> </span> <strong><i>My current research interests include a series of topics: multimodal learning, knowledge-informed machine learning, multimodal few/zero-shot learning, meta learning, and spatio-temporal data mining.</i></strong>     
    </div>
	

 <tr><tr><tr><tr>
<div style="margin-top: 10px"></div>
    <h2>Publications </h2>
<!--<p><a href="http://scholar.google.com/citations?user=PeMuphgAAAAJ">My Google Scholar</a></p>-->
<table id="tbPublications" width="100%">
	<tbody>
<h3 style="color: red">Preprints</h3>
	
   <tr>	
		<td width="206">
		<img src="img/metadiff.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">MetaDiff: Meta-Learning with Conditional Diffusion for Few-Shot Learning.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Demin Yu.</p>
        <p class="post-date" style="margin-top: -10px" ><i>arXiv preprint arXiv: 2307.16424</i>, 2023. <strong>
		[<a href="https://arxiv.org/abs/2307.16424">arXiv</a>] 
		[<a href="https://arxiv.org/abs/2307.16424.pdf">PDF</a>]</strong></p>
		</td>
	</tr>
	
	<tr></tr>
    <tr></tr>
    <tr></tr>
 </tbody>
</table>
	      
<table id="tbPublications" width="100%">
<tbody>
<h3 style="color: red">Conference Papers </h3>
<tr>
	
		<td width="206">
		<img src="img/metadiff.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">MetaDiff: Meta-Learning with Conditional Diffusion for Few-Shot Learning.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Chuyao Luo, Demin Yu, Xutao Li, Huiwei Lin, Yunming Ye, and Bowen Zhang.</p>
        <p class="post-date" style="margin-top: -10px" ><i>Thirty-Sixth AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2024. <strong>(CCF-A)</strong></i>.
		[<a href="https://arxiv.org/abs/2307.16424">arXiv</a>] 
		[<a href="https://arxiv.org/abs/2307.16424.pdf">PDF</a>]</strong></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>	
	
<tr>
<tr>
	
		<td width="206">
		<img src="img/pcr.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank"> PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning.</a><strong>[<a href="">PDF</a>]</strong><strong>[<a href="">arXiv</a>]</strong><strong>[<a href="">Code</a>]</strong><br>
		 <p > Huiwei Lin, <strong>Baoquan Zhang</strong>, Shanshan Feng, Xutao Li, Yunming Ye*.</p>
       <p style="margin-top: -11px"><i> IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2023. <strong>(CCF-A)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>	
	
<tr>
	
		<td width="206">
		<img src="img/HyperKT.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank"> Hyperbolic Knowledge Transfer with Class Hierarchy for Few-Shot Learning.</a><strong>[<a href="">PDF</a>]</strong><strong>[<a href="https://www.ijcai.org/proceedings/2022/0517.pdf">arXiv</a>]</strong><strong>[<a href="https://www.ijcai.org/proceedings/2022/0517.pdf">Code</a>]</strong><br>
		 <p ><strong>Baoquan Zhang</strong>, Hao Jiang, Shanshan Feng, Xutao Li, Yunming Ye*, Rui Ye.</p>
       <p style="margin-top: -11px"><i> The 31st International Joint Conference on Artificial Intelligence (<strong> IJCAI </strong>), 2022. <strong>(CCF-A)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	
<tr>
	
		<td width="206">
		<img src="img/MetaNODE.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank"> MetaNODE: Prototype Optimization as a Neural ODE for Few-Shot Learning.</a><strong>[<a href="https://arxiv.org/pdf/2103.14341.pdf">PDF</a>]</strong><strong>[<a href="https://arxiv.org/abs/2103.14341">arXiv</a>]</strong><strong>[<a href="https://github.com/zhangbq-research/metanode">Code</a>]</strong><br>
		 <p ><strong>Baoquan Zhang</strong>, Xutao Li*, Shanshan Feng, Yunming Ye*, Rui Ye.</p>
       <p style="margin-top: -11px"><i>Thirty-Sixth AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2022. <strong>(CCF-A)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	
<tr>
	
		<td width="206">
		<img src="img/PrototypeCompletionCVPR.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank"> Prototype Completion with Primitive Knowledge for Few-Shot Learning.</a><strong>[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Prototype_Completion_With_Primitive_Knowledge_for_Few-Shot_Learning_CVPR_2021_paper.pdf">PDF</a>]</strong><strong>[<a href="https://arxiv.org/pdf/2009.04960.pdf">arXiv</a>]</strong><strong>[<a href="https://github.com/zhangbq-research/Prototype_Completion_for_FSL">Code</a>]</strong><br>
		 <p ><strong>Baoquan Zhang</strong>, Xutao Li*, Yunming Ye*, Zhichao Huang, Lisai Zhang.</p>
       <p style="margin-top: -11px"><i>IEEE Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2021. <strong>(CCF-A)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>

		
<table id="tbPublications" width="100%">
<tbody>	
<h3 style="color: red">Journal Papers</h3>
   <tr>	
		<td width="206">
		<img src="img/penet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">PEPNet: A barotropic primitive equations-based network for wind speed prediction.</a><br>
		<p >Rui Ye, <strong>Baoquan Zhang</strong>*, Xutao Li, Yunming Ye.</p>
        <p class="post-date" style="margin-top: -10px" ><i>Neural Networks (NN)</i>, 2023. <strong>
		[<a href="https://www.sciencedirect.com/science/article/pii/S089360802300463X">PDF</a>]</strong></p>
		</td>
	</tr>

   <tr>	
		<td width="206">
		<img src="img/TRCDNet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">TRCDNet: A Transformer Network for Video Cloud Detection.</a><br>
		<p >Chen Luo, Shanshan Feng, Yingling Quan, Yunming Ye, Xutao Li, Yong Xu, <strong>Baoquan Zhang</strong>, Zhihao Chen.</p>
        <p class="post-date" style="margin-top: -10px" ><i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i>, 2023. <strong>
		[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10175078">PDF</a>]</strong></p>
		</td>
	</tr>
	
   <tr>	
		<td width="206">
		<img src="img/PrototypeCompletion.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">Prototype Completion for Few-Shot Learning.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Xutao Li*, Yunming Ye*, Shanshan Feng.</p>
        <p class="post-date" style="margin-top: -10px" ><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2023. <strong>
		[<a href="https://arxiv.org/abs/2108.05010">arXiv</a>] 
		[<a href="https://arxiv.org/pdf/2108.05010.pdf">PDF</a>]</strong></p>
		</td>
	</tr>
	
   <tr>	
		<td width="206">
		<img src="img/MetaDT.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">MetaDT: Meta Decision Tree for Interpretable Few-Shot Learning.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Hao Jiang, Xutao Li, Shanshan Feng, Yunming Ye*, Chen Luo, Rui Ye.</p>
        <p class="post-date" style="margin-top: -10px" ><i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</i>, 2022. <strong>
		[<a href="https://arxiv.org/abs/2203.01482">arXiv</a>] 
		[<a href="https://ieeexplore.ieee.org/abstract/document/10130710/">PDF</a>]</strong></p>
		</td>
	</tr>
	
   <tr>	
		<td width="206">
		<img src="img/SGMNet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">SGMNet: Scene Graph Matching Network for Few-Shot Remote Sensing Scene Classification.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Shanshan Feng, Xutao Li, Yunming Ye*, Rui Ye.</p>
        <p class="post-date" style="margin-top: -10px" ><i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i>, 2022. <strong>
		[<a href="https://arxiv.org/abs/2110.04494">arXiv</a>] 
		[<a href="https://ieeexplore.ieee.org/document/9869702/authors#authors">PDF</a>](SCI, IF=8.125, CCF-B)</strong></p>
		</td>
	</tr>
	
    <tr>	
		<td width="206">
		<img src="img/MetaConcept.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">Learn to Abstract via Concept Graph for Weakly-Supervised Few-Shot Learning.</a><br>
		<p ><strong>Baoquan Zhang</strong>, Ka-Cheong Leung, Xutao Li, Yunming Ye*.</p>
	       <p style="margin-top: -11px"><i>Pattern Recognition (<strong> PR </strong>), 2021, accepted. <strong>
		 [<a href="https://arxiv.org/pdf/2007.02379.pdf">arXiv</a>] [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001333">PDF</a>](SCI, IF=8.518, CCF-B)</strong></p>
		</td>
	</tr>
	<tr></tr>
	
    <tr>	
		<td width="206">
		<img src="img/" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">DynamicNet: A time-variant ODE network for multi-step wind speed prediction.</a><br>
		<p >Rui Ye, Xutao Li, Yunming Ye*, <strong>Baoquan Zhang</strong>.</p>
	       <p style="margin-top: -11px"><i>Neural Networks (<strong> NN </strong>), 2022, accepted. <strong>
		 [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608022001356?casa_token=-wW7yLGLbp0AAAAA:ltDwRyfoAP2KLwXabcUiB6vW19RhMUGCMRP1t8V28UZBqhGCHcRDYexwl_7dLCy9pZRlt_yjFe8K">PDF</a>](SCI, IF=8.05, CCF-B)</strong></p>
		</td>
	</tr>
	<tr></tr>	
	
    <tr>	
		<td width="206">
		<img src="img/" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="" target="_blank">ECDNet: A Bilateral Lightweight Cloud Detection Network for Remote Sensing Images.</a><br>
		<p >Chen Luo, Shanshan Feng, Xutao Li, Yunming Ye*, <strong>Baoquan Zhang</strong>, Zhihao Chen, YingLing Quan.</p>
	       <p style="margin-top: -11px"><i>Pattern Recognition (<strong> PR </strong>), 2022, accepted. <strong>
		 [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322001947">PDF</a>](SCI, IF=8.518, CCF-B)</strong></p>
		</td>
	</tr>
	<tr></tr>

    <tr></tr>
    <tr></tr>

</tbody>
</table>




  </div>



      <h2 >News</h2>
    <div id = "news-content" style="margin-top: 15px">
      <li style="margin: -10px 0px 0px 5px" ><span style="color:Red">2023.12.09</span>, one paper is accepted by <strong><i>AAAI 2024</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.10.25</span>, one paper is accepted by <strong><i>IEEE/ACM Transactions on Computational Biology and Bioinformatics</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.09.10</span>, one corresponding author paper is accepted by <strong><i>Neural Networks (NN)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.07.07</span>, one co-author paper is accepted by <strong><i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.05.04</span>, one paper is accepted by <strong><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.02.28</span>, one co-author paper is accepted by <strong><i>CVPR'2023</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.02.26</span>, I have successfully passed the Ph.D. Oral Defence. You may call me Dr.Zhang from now.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2023.02.17</span>, one co-author paper is accepted by <strong><i>Neural Networks (NN)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.12.03</span>, one paper is accepted by <strong><i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.08.16</span>, one paper is accepted by <strong><i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.07.02</span>, one co-author paper is accepted by <strong><i>Information Science</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.05.02</span>, one co-author paper is accepted by <strong><i>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.04.21</span>, one paper is accepted by <strong><i>IJCAI'2022</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.04.14</span>, one co-author paper is accepted by <strong><i>Pattern Recognition (PR)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.04.06</span>, one co-author paper is accepted by <strong><i>Neural Networks (NN)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2021.12.01</span>, one paper is accepted by <strong><i>AAAI'2022</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2021.03.07</span>, one paper is accepted by <strong><i>Pattern Recognition (PR)</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2021.03.01</span>, one paper is accepted by <strong><i>CVPR'2021</i></strong>.</li>
      <li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2019.03.01</span>, I start my Ph.D study in ICES at <strong>HITSZ</strong>.</li>
    </div>

<div id="footer">
    <div id="footer-text"></div>
</div>
<div id="logo" style="margin-top: 10px; text-align:center">
    <div align="center" style="margin:auto;padding-top:10px">
        <br>
        &copy;| <span id="last-updated" style="color:Red">Last updated: December 12 2021</span>
    </div>
</div>

<script>
    function updateLastUpdatedDate() {
        var currentDate = new Date();
        var formattedDate = currentDate.toLocaleDateString('en-US', { month: 'long', day: 'numeric', year: 'numeric' });
        document.getElementById('last-updated').textContent = 'Last updated: ' + formattedDate;
    }

    // 在页面加载时调用函数，设置初始日期
    updateLastUpdatedDate();

    // （可选）如果需要在每次页面更新时自动更改日期，可以调用函数
    // updateLastUpdatedDate();
</script>


</body></html>
